# ETL-101-Data-Wash ğŸ§¼ğŸš€  

## ğŸ“Œ Project Description  
This project is a **modular ETL pipeline** designed to extract, clean, and save a dataset from Kaggle. The dataset used is from **Spotify**, and the goal is to process raw data into a structured format ready for analysis.  

The pipeline follows a standard ETL process:  
âœ… **Extract** â€“ Download data from Kaggle  
âœ… **Transform** â€“ Clean and preprocess the dataset  
âœ… **Load** â€“ Save the cleaned dataset for further analysis  

---

## ğŸ“‚ Project Structure  
```
etl-101-data-wash/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ extract.py   # Downloads dataset from Kaggle
â”‚   â”œâ”€â”€ transform.py # Cleans and preprocesses data
â”‚   â”œâ”€â”€ load.py      # Saves the cleaned dataset
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ processed/   # Folder for cleaned data
â”‚   â”œâ”€â”€ raw/         # Folder for raw data
â”‚â”€â”€ main.py          # Orchestrates the entire ETL process
â”‚â”€â”€ poetry.lock
â”‚â”€â”€ pyproject.toml
â”‚â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack  
- ğŸ **Python** â€“ Core programming language  
- ğŸ“¦ **Poetry** â€“ Dependency management  
- ğŸ“Š **Pandas** â€“ Data manipulation  
- ğŸ’¾ **Kaggle API** â€“ Dataset extraction  

---

## ğŸš€ How to Run  

### **1ï¸âƒ£ Install Dependencies**  
Ensure you have **Poetry** installed, then run:  
```bash
poetry install
```

### **2ï¸âƒ£ Configure Kaggle API**  
If you haven't set up the Kaggle API yet, follow these steps:  
1ï¸âƒ£ Go to [Kaggle Account](https://www.kaggle.com/settings)  
2ï¸âƒ£ Scroll to the **API** section and click **Create New Token**  
3ï¸âƒ£ Move the downloaded `kaggle.json` file to:  
   - **Linux/Mac**: `~/.kaggle/kaggle.json`  
   - **Windows**: `C:\Users\YOUR_USER\.kaggle\kaggle.json`  
4ï¸âƒ£ Set permissions (Linux/Mac only):  
```bash
chmod 600 ~/.kaggle/kaggle.json
```

### **3ï¸âƒ£ Run the ETL Pipeline**  
To execute the complete ETL process, run:  
```bash
poetry run python main.py
```

This will:  
âœ”ï¸ Download the dataset  
âœ”ï¸ Clean and preprocess the data  
âœ”ï¸ Save the cleaned dataset in `data/processed/spotify_cleaned.csv`

---

## ğŸ“Š Output Data  
The cleaned dataset is saved in:  
```
data/processed/spotify_cleaned.csv
```
This file is ready for analysis and further processing.  

---

## ğŸŒŸ Next Steps  
ğŸ”¹ Automate execution with Apache Airflow  
ğŸ”¹ Store cleaned data in a cloud database (Snowflake, BigQuery)  
ğŸ”¹ Add data validation checks  

---

## ğŸ“œ License  
This project is open-source and available under the **MIT License**. Feel free to use and contribute!  

---

ğŸš€ **Happy Data Cleaning!** ğŸ§¼ğŸ“Š